{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f08b840-f3ec-4f5f-9d61-227f65266e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 71 files to the new cache system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d1dffdabf44dbb9f118a172e654a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import whisper\n",
    "\n",
    "import numpy as np\n",
    "import librosa as lr\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7e2d0a-4857-41bc-8046-2c21eb26547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device mps\n"
     ]
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.backends.cuda.is_available() else 'cpu'\n",
    "print(f'Torch device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffeaa4a4-ef97-4420-b1a3-1800679e1152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with clang version 14.0.4\n",
      "  configuration: --prefix=/Users/runner/miniforge3/conda-bld/ffmpeg_1666357556406/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl --cc=arm64-apple-darwin20.0.0-clang --cxx=arm64-apple-darwin20.0.0-clang++ --nm=arm64-apple-darwin20.0.0-nm --ar=arm64-apple-darwin20.0.0-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-cross-compile --arch=arm64 --target-os=darwin --cross-prefix=arm64-apple-darwin20.0.0- --host-cc=/Users/runner/miniforge3/conda-bld/ffmpeg_1666357556406/_build_env/bin/x86_64-apple-darwin13.4.0-clang --enable-neon --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --pkg-config=/Users/runner/miniforge3/conda-bld/ffmpeg_1666357556406/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'lex_short.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    creation_time   : 2022-10-20T04:06:15.000000Z\n",
      "  Duration: 00:02:07.64, start: 0.000000, bitrate: 275 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1280x720 [SAR 1:1 DAR 16:9], 142 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-10-20T04:06:15.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 10/19/2022.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2022-10-20T04:06:15.000000Z\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 10/19/2022.\n",
      "      vendor_id       : [0][0][0][0]\n",
      "File 'lex_short.wav' already exists. Overwrite? [y/N] Not overwriting - exiting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvideo = 'lex_short.mp4'\n",
    "# with open('lex_short.mp4', 'rb') as f:\n",
    "#     lex_short = f.read()\n",
    "\n",
    "# print(f'Read file of length {len(lex_short) / 1024 / 1024:.2f} MB')\n",
    "\n",
    "import subprocess\n",
    "\n",
    "paudio = 'lex_short.wav'\n",
    "command = f'ffmpeg -i {pvideo} -ab 160k -ac 2 -ar 44100 -vn {paudio}'\n",
    "\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9369570c-b5d4-4648-99b9-3849e5195cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2042242,), 16000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio, sample_rate = lr.load(paudio, sr=16000)\n",
    "audio.shape, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "274bb1f0-4b1e-4497-911e-babcd5b1585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is English-only and has 240,582,144 parameters.\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"small.en\")\n",
    "print(\n",
    "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc61fc89-114f-4c9b-8df7-eba3cc285965",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = whisper.DecodingOptions(language='en', without_timestamps=False, fp16 = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32a00611-03cd-4c6b-b98a-20b8efb145ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunks = np.array_split(audio.flatten(), audio.shape[0] // 80000)\n",
    "# chunks = [audio[i : i + 90000] for i in range(0, audio.shape[0], 89000)]\n",
    "split = lr.effects.split(audio, top_db=60)\n",
    "chunks = []\n",
    "for b, e in split:\n",
    "    chunks.append(audio[b:e])\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfc3f3de-abd6-4f44-887e-6b42694898b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mels = []\n",
    "for chunk in chunks:\n",
    "    if sum(chunk) == 0.0:\n",
    "        continue\n",
    "\n",
    "    taudio = whisper.pad_or_trim(torch.tensor(chunk)).to('cpu')\n",
    "    mel = whisper.log_mel_spectrogram(taudio)\n",
    "    mels.append(mel.numpy())\n",
    "    # tmel = torch.tensor(np.array([mel.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca6687cd-ab54-409c-8102-61ae40d22239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 54s, sys: 32.2 s, total: 2min 26s\n",
      "Wall time: 43.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "texts = []\n",
    "batch_size = 16\n",
    "# for mel in np.array_split(mels, batch_size):\n",
    "tmel = torch.tensor(np.array(mels))\n",
    "results = model.decode(tmel, options)\n",
    "texts.extend([result.text for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "423d995d-9b2f-44a2-b0b4-8b0a8a224585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What makes Magnus so good? What are the various aspects of his game that make him so good?',\n",
       " 'I think for Magnus, he just.',\n",
       " \"You know that in the end game, in the end games, if you get there, he's just he's not going to blunder. That's the first thing. So you know, if you reach an end game, he's not going to make a mistake. He obviously plays great openings.\",\n",
       " \"And there's just really no defined weakness that he has. There's no weakness that I can think of very specifically. There are many times where players actually out-prepare him in the opening phase, but as soon as they're on their own and they have to think...\",\n",
       " \"very often times they'll make mistakes. So there's just no weakness for Magnus, really no weakness. Unlike say Kasparov, like Kasparov on the other hand, there are very clear weaknesses in his game like Kramnik exploited them. First of all, very, I don't wanna say like.\",\n",
       " \"Ego is the right word, but like very stubborn, believing that his openings were infallible, that he could just win. He could just prove an advantage and win the game out of the opening, like against Kramnik when he ultimately lost. Also generally not a great defender either. Very strong tactically. But if he was in positions that were defensive, he would make mistakes and lose in end games like he did in one of those games in the world championship against Kramnik. So there were very clear defined weaknesses in Kasparov's game.\",\n",
       " \"Whereas like Magnus are just there no clearly defined weaknesses. Maybe maybe he doesn't like being attacked.\",\n",
       " \"Maybe that's the one thing. He likes King safety and he doesn't like being attacked, but that's not something that you can easily do. Whereas say if someone's very tactical and they're not a strong positionally, that is something you can def, that will happen quite frequently in games. You can steer games a certain way. Doesn't mean you'll always get there, but that is something tangible. Whereas King safety, that's not something tangible at all. It's very, very hard to attack someone based on, unless they play certain style of openings.\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4252bdb-8c43-4d8a-b0ed-28d8f7ee5b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "122ccd47-bb39-4613-a94d-dac90021b007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 9.5 s, total: 1min 48s\n",
      "Wall time: 1min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Qu’est-ce qui fait de Magnus si bon? Quels sont les divers aspects de son jeu qui le rendent si bon?',\n",
       " \"Je pense à Magnus, c'est lui.\",\n",
       " \"Vous savez qu'à l'issue du jeu, à l'issue du jeu, si vous y arrivez, il ne va pas blâmer. C'est la première chose. Donc, vous savez, si vous arrivez à l'issue du jeu, il ne fera pas d'erreur. Il joue évidemment de grands ouvertures.\",\n",
       " \"Et il n'y a vraiment pas de faiblesse définie qu'il a. Il n'y a pas de faiblesse que je puisse envisager très spécifiquement. Il y a de nombreuses fois où les joueurs l'ont vraiment out-preparé dans la phase d'ouverture, mais dès qu'ils sont seuls et qu'ils doivent penser...\",\n",
       " \"c'est pourquoi il n'y a pas de faiblesse pour Magnus, vraiment pas de faiblesse. À l'instar de Kasparov dit Kasparov, comme Kasparov d'autre part, il y a des faiblesses très claires dans son jeu comme Kramnik les exploite comme Kramnik les exploite. Tout d'abord, très, je ne veux pas dire comme.\",\n",
       " \"Ego est la bonne parole, mais comme très tenace, croyant que ses ouvertures étaient infaillibles, qu'il pouvait simplement gagner. Il pouvait simplement prouver un avantage et gagner le jeu à l'extérieur de l'ouverture, comme contre Kramnik quand il a finalement perdu. En outre généralement pas un grand défenseur ni un grand défenseur ni. Très fort tactiquement. Très fort tactiquement. Mais si il était dans des positions qui étaient défensives, il ferait des erreurs et perdrait dans les matchs finals comme il l'a fait dans l'un de ces matchs de la championne mondiale contre Kramnik. Donc, il y avait des faiblesses très clairement définies dans le jeu de Kasparov.\",\n",
       " 'Alors qu’à l’instar de Magnus, il n’y a pas de faiblesses clairement définies. Peut-être peut-être il n’aime pas être attaqué.',\n",
       " \"Peut-être c'est l'une des choses. Il aime la sécurité de King et il n'aime pas être attaqué, mais c'est pas quelque chose que vous pouvez facilement faire. Alors que dire si quelqu'un est très tactique et qu'il n'est pas fort positionnellement, c'est quelque chose que vous pouvez déférer, ce qui se produira très fréquemment dans les jeux. Vous pouvez diriger les jeux d'une certaine façon. Cela ne signifie pas que vous y arriverez toujours, mais c'est quelque chose tangible. Alors que la sécurité de King, ce n'est pas tout à fait quelque chose tangible. Il est très, très difficile d'attaquer quelqu'un en se fondant sur, à moins qu'il ne joue un certain style d'ouvertures.\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer.src_lang = \"en_IN\"\n",
    "translated = []\n",
    "for text in texts:\n",
    "    encoded_en = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    generated_tokens = model.generate(\n",
    "        **encoded_en,\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[\"fr_XX\"]\n",
    "    )\n",
    "    result = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "    translated.append(result)\n",
    "\n",
    "translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ffc8586-6f1a-41ea-8086-1a4f44ea9e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting speechbrain\n",
      "  Downloading speechbrain-0.5.13-py3-none-any.whl (498 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.0/499.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from speechbrain) (21.3)\n",
      "Requirement already satisfied: sentencepiece in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from speechbrain) (0.1.97)\n",
      "Requirement already satisfied: torch>=1.9 in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from speechbrain) (1.12.1)\n",
      "Collecting hyperpyyaml\n",
      "  Downloading HyperPyYAML-1.0.1.tar.gz (14 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from speechbrain) (0.10.1)\n",
      "Requirement already satisfied: torchaudio in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from speechbrain) (0.12.1)\n",
      "Requirement already satisfied: scipy in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from speechbrain) (1.9.3)\n",
      "Requirement already satisfied: joblib in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from speechbrain) (1.2.0)\n",
      "Requirement already satisfied: numpy in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from speechbrain) (1.23.4)\n",
      "Requirement already satisfied: tqdm in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from speechbrain) (4.64.1)\n",
      "Requirement already satisfied: typing_extensions in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from torch>=1.9->speechbrain) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from huggingface-hub->speechbrain) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from huggingface-hub->speechbrain) (3.8.0)\n",
      "Requirement already satisfied: requests in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from huggingface-hub->speechbrain) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from packaging->speechbrain) (3.0.9)\n",
      "Collecting ruamel.yaml>=0.17.8\n",
      "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ruamel.yaml.clib>=0.2.6\n",
      "  Downloading ruamel.yaml.clib-0.2.7-cp39-cp39-macosx_12_0_arm64.whl (130 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from requests->huggingface-hub->speechbrain) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from requests->huggingface-hub->speechbrain) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from requests->huggingface-hub->speechbrain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/andrei/miniforge3/envs/nlp/lib/python3.9/site-packages (from requests->huggingface-hub->speechbrain) (2022.9.24)\n",
      "Building wheels for collected packages: hyperpyyaml\n",
      "  Building wheel for hyperpyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hyperpyyaml: filename=HyperPyYAML-1.0.1-py3-none-any.whl size=15174 sha256=4c1ca9eef92c53e7faa8718fc3b4c6f90967cd1b6495f8f11408a8e267b5b8b5\n",
      "  Stored in directory: /Users/andrei/Library/Caches/pip/wheels/a8/6f/8f/c1912060e1a1c387c8667df7581c4c10a70066903a19bdabe8\n",
      "Successfully built hyperpyyaml\n",
      "Installing collected packages: ruamel.yaml.clib, ruamel.yaml, hyperpyyaml, speechbrain\n",
      "Successfully installed hyperpyyaml-1.0.1 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.7 speechbrain-0.5.13\n"
     ]
    }
   ],
   "source": [
    "!pip install speechbrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad49050f-f264-4199-8bee-d3c6d172406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from speechbrain.pretrained import Tacotron2\n",
    "from speechbrain.pretrained import HIFIGAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e38d559f-0644-42ec-9813-8c1f6bf7aad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e79d97836146c9950e282dfeeccf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad1d71530864c8dbca021a64197bbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/113M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189b856ce5b246d89f00a6354705b143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1b4d71475547b1899127c6321a343a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/55.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tacotron2 = Tacotron2.from_hparams(source=\"speechbrain/tts-tacotron2-ljspeech\", savedir=\"tmpdir_tts\")\n",
    "hifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-ljspeech\", savedir=\"tmpdir_vocoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5610e15-58ac-4c6b-ac0f-c86d2c044a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_output, mel_length, alignment = tacotron2.encode_text(translated[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cb07020-fce3-4a20-8047-55ac1e528437",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = hifi_gan.decode_batch(mel_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e0c2c02-dbf0-4aaa-9b4e-11c924363b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save('example_TTS.wav',waveforms.squeeze(1), 22050)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
